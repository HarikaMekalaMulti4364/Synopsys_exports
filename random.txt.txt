import argparse
import collections
import json
import math
import os
import pickle
import subprocess
import sys
from typing import Any, Dict, List

import numpy as np
import six

from transformers import BertTokenizer

# Import functions from your script
from create_squad_data import convert_examples_to_features, read_squad_examples
from utils import load_loadgen_log, write_predictions

# Define dtype map
dtype_map = {
    "int8": np.int8,
    "int16": np.int16,
    "int32": np.int32,
    "int64": np.int64,
    "float16": np.float16,
    "float32": np.float32,
    "float64": np.float64
}

def postprocess(nn_outputs: Dict[str, Any]) -> str:
    parser = argparse.ArgumentParser()
    parser.add_argument("--vocab_file", default="build/data/bert_tf_v1_1_large_fp32_384_v2/vocab.txt", help="Path to vocab.txt")
    parser.add_argument("--val_data", default="build/data/dev-v1.1.json", help="Path to validation data")
    parser.add_argument("--log_file", default="build/logs/mlperf_log_accuracy.json", help="Path to LoadGen accuracy log")
    parser.add_argument("--out_file", default="build/result/predictions.json", help="Path to output predictions file")
    parser.add_argument("--features_cache_file", default="eval_features.pickle", help="Path to features' cache file")
    parser.add_argument("--output_transposed", action="store_true", help="Transpose the output")
    parser.add_argument("--output_dtype", default="float32", choices=dtype_map.keys(), help="Output data type")
    parser.add_argument("--max_examples", type=int, help="Maximum number of examples to consider (not limited by default)")
    args = parser.parse_args([])  # Use empty list to prevent conflict with Jupyter notebook arguments

    output_dtype = dtype_map[args.output_dtype]

    print("Reading examples...")
    eval_examples = read_squad_examples(input_file=args.val_data, is_training=False, version_2_with_negative=False)

    eval_features = []
    # Load features if cached, convert from examples otherwise.
    cache_path = args.features_cache_file
    if os.path.exists(cache_path):
        print("Loading cached features from '%s'..." % cache_path)
        with open(cache_path, 'rb') as cache_file:
            eval_features = pickle.load(cache_file)
    else:
        print("No cached features at '%s'... converting from examples..." % cache_path)

        print("Creating tokenizer...")
        tokenizer = BertTokenizer(args.vocab_file)

        print("Converting examples to features...")

        def append_feature(feature):
            eval_features.append(feature)

        convert_examples_to_features(
            examples=eval_examples,
            tokenizer=tokenizer,
            max_seq_length=max_seq_length,
            doc_stride=doc_stride,
            max_query_length=max_query_length,
            is_training=False,
            output_fn=append_feature,
            verbose_logging=False)

        print("Caching features at '%s'..." % cache_path)
        with open(cache_path, 'wb') as cache_file:
            pickle.dump(eval_features, cache_file)

    # Load LoadGen logs
    results = load_loadgen_log(args.log_file, eval_features, output_dtype, args.output_transposed)

    # Post-process predictions
    print("Post-processing predictions...")
    write_predictions(eval_examples, eval_features, results, 20, 30, True, args.out_file, args.max_examples)

    print("Evaluating predictions...")
    cmd = f"python3 {os.path.dirname(os.path.abspath(__file__))}/evaluate_v1.1.py {args.val_data} {args.out_file}"
    if args.max_examples:
        cmd += f" --max_examples {args.max_examples}"
    subprocess.check_call(cmd, shell=True)

    return args.out_file

# Example usage:
# nn_outputs = [(start_logits1, end_logits1), (start_logits2, end_logits2), ...]
# postprocess(nn_outputs)
